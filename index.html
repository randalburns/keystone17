<!DOCTYPE html>
<html>
  <head>
    <!-- <link href="https://file.myfontastic.com/n6vo44Re5QaWo8oCKShBs7/icons.css" rel="stylesheet"> -->

    <!-- bootstrap icons -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- font awesome icons -->
    <link rel="stylesheet" href="css/font-awesome-4.6.3/css/font-awesome.min.css">
    
    <!-- google web fonts -->
    <!-- <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"> -->

    <!-- bower:css -->
    <!-- <link rel="stylesheet" href="/content/themes/jhu_id/bower_components/normalize-css/normalize.css"> -->
    <link rel="stylesheet" href="fonts/gentona/gentona.css">
    <link rel="stylesheet" href="fonts/titling-gothic/titling-gothic.css">
    <link rel="stylesheet" href="fonts/quadon/quadon.css">
    <link rel="stylesheet" href="fonts/arnhem/arnhem.css">
    <!-- endbower -->

    <title>NeuroData Intro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">

      body {
        font-family: 'gentona'; /* Varela Round */
        font-size: 1.6em;
      }
      /*      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
      }      */
      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
        font-weight: 400;
        margin-bottom: 0;
        color: #d5ad6d;
/*        color:  #D5AD6D; /*if no support for background-clip*/
  
        /*background: -webkit-linear-gradient(transparent, transparent),*/
             /*-webkit-linear-gradient(top, rgba(213,173,109,1) 0%, rgba(213,173,109,1) 26%, rgba(226,186,120,1) 35%, rgba(163,126,67,1) 45%, rgba(145,112,59,1) 61%, rgba(213,173,109,1) 100%);*/
        /*background: -o-linear-gradient(transparent, transparent);*/
  /*-webkit-background-clip: text;*/
  /*-webkit-text-fill-color: transparent;*/

      }
      .remark-slide-content {
        font-size: 1.5em;
        background: #272822;
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */
        background: -webkit-radial-gradient(circle, #272822, #15120e, black); /* Safari */
        background: -o-radial-gradient(circle, #272822, #15120e, black); /* Opera 11.6 to 12.0 */
        background: -moz-radial-gradient(circle, #272822, #15120e, black); /* Firefox 3.6 to 15 */
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */

        color: #ebd8b9; /*#f4e9d8;*/ /*#debe8b;*/ /*#6dd5ad;*/ /*rgba(213,173,109,1);*/ /*rgba(163,126,67,1);*/ /*rgba(226,186,120,1);*/ /*rgba(213,173,109,1);*/ /*#6dd5ad;*/
        /*background: #3B263C;*/
  /*        color:  #FFFF00; /*#DDA0DD;*/  /*#A565D6;*/ /* #DF9BFF;*/ /*#FFFF00;*/*/
      }

      h1, h2, h3, h4 {
        text-align: center;
        /*text-shadow: 2px 2px gray; /*#ff0000;*/*/
      }

      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .remark-slide-content h4 { font-size: 1.4em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .navbar {
        position: absolute;
        float: center;
        top: 0em;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .navbar a {
        color: #A7A7A7;
      }
      .bbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .bbar a {
        color: #A7A7A7;
      }
      .cbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        /*color: #A7A7A7;*/
        color: #bdbcbc;
      }
      .cbar a{
       color: #bdbcbc; 
      }

      .btn {
        background: #424242;
        height: 2em;
      }
      li p { line-height: 1.25em; }
      .r { color: #fa0000; }
      .w {color: white;}
      .ye { color: #FFFF00; }
      .y { color: #fcfaf6; }
      .pink { color: #FF87F3;}
      .orange { color: #FFA500;}
      .g { color: #00CC00; }
      .blue { color: #75E9FF;}
      .purple { color: #A149A9;}
      .large { font-size: 2em; }
      .black { color: black; background-color: white;}
      a, a > code {
        color:  rgb(249, 38, 114); 
        color: white; 
        color: #bdbcbc; 
        /*color: #b1b1b1;*/
        text-decoration: none; /*underline*/
      }

      a:hover {
        color: white;
      }


      code {
        background: #424242;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
/*      .pull-left {
        float: left;
        width: 47%;
      }*/
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .small {
        font-size: 0.8em;
      }
/*      .pull-right {
        float: right;
        width: 47%;
      }*/
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .bottom {
        position: absolute;
        bottom: 35px;
        left: 13px;
        font-family: 'Yanone Kaffeesatz';
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: white;
        color: white;
        text-shadow: 0 0 20px #333;
      }
      .inverse p {
        color: white;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }
      #frame { zoom: 0.75; -moz-transform: scale(0.75); -moz-transform-origin: 0 0; }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

.column:first-of-type {float:left}
.column:last-of-type {float:right}

.split-20 .column:first-of-type {width: 20%}
.split-20 .column:last-of-type {width: 80%}
.split-30 .column:first-of-type {width: 30%}
.split-30 .column:last-of-type {width: 70%}
.split-40 .column:first-of-type {width: 40%}
.split-40 .column:last-of-type {width: 60%}
.split-50 .column:first-of-type {width: 50%}
.split-50 .column:last-of-type {width: 50%}
.split-60 .column:first-of-type {width: 60%}
.split-60 .column:last-of-type {width: 40%}
.split-70 .column:first-of-type {width: 70%}
.split-70 .column:last-of-type {width: 30%}
.split-80 .column:first-of-type {width: 80%}
.split-80 .column:last-of-type {width: 20%}

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-child {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 50%;
      }
      .task {
        float: right;
        font-size: 0.9em;
        padding-top: 0.6em;
      }

  }
    </style>
  </head>
  <body onload="var slideshow = remark.create();">
    <textarea id="source">



class: center, middle

name:opening

## Data-Intensive Applications:
## [The OpenConnectome Project](http://openconnecto.me)
### A [NeuroData](http://neurodata.io) Project


<br>

.center[
Randal Burns
<br>
{[CS](http://www.cs.jhu.edu/),[KNDI](http://idies.jhu.edu/),[IDIES](http://idies.jhu.edu/)}@[JHU](https://www.jhu.edu/)
<br>
please ask questions: [support@neurodata.io](mailto:support at neurodata dot io)
<br>
these slides: <http://docs.neurodata.io/keystone.ocp17>

]


---
class: center, middle

### NeuroData Data


<!-- https://openwiki.janelia.org/wiki/download/attachments/34505478/Image%201%20-%20Medulla%20EM%20Stack%20-%20Final.jpg?version=1&modificationDate=1375908720000&api=v2 -->


<!-- ### Opportunity: Big Neuro Data -->

<!-- .center[6 panel nd website figure] -->


<img src="images/oppo/em.jpg"/>
<img src="images/oppo/at.png"/>
<img src="images/oppo/clarity.jpg"/>
<img src="images/oppo/xbrain.png"/>
<img src="images/oppo/fibers.jpg"/>
<img src="images/oppo/mri.png"/>


---


## Challenge #1

.center[
<iframe width="600" height="420" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]


Goal: Enable generating and confirming anatomical hypotheses on a 20 Teravoxel volume in a reproducible and extensible fashion.


---

## Challenge #2


.center[
<iframe width="720" height="400" src="https://www.youtube.com/embed/jziqfFp9Rq0" frameborder="0" allowfullscreen></iframe>
]

Goal: Build a taxomony of synapses through the analysis and clustering of conjugate EM and protein expression in array tomography.

---

<img src="images/ocp.png" alt="Drawing" style="width: 700px;"/>

<br> 

Founded to create an infrastructure for the __open-science, data-intensive analysis of electron microscopy brain data__
- peta-scale storage linked to HPC
- computational vision workflows to extract brain structure
- spatial queries (clusters, volumes, distributions) for analysis

Evolved into an end-to-end (from microscope output to publication) platform for data management and reproducible science
- visualiztion in 2-d and 3-d with mobile support
- image processing: stitching, alignment, registration, color correction 
- cloud-based storage, processing, and caching
- Web-services back end for many visualization tools ([BigDataViewer](https://imagej.net/BigDataViewer), [CATMAID](http://catmaid.readthedocs.io/), [NeuroGlancer](https://neuroglancer-demo.appspot.com/))

---

### OCP Architecture (ca. 2013)

<br> 

Scale-out storage clusters that provide data through Web services
- cutout: read a spatial volume of data
- annotate: label regions of space (store superpixelations)
- query: shapes, objects metadata

<br>

.left[
<img src="images/ocp2013.png" alt="Drawing" style="width: 700px;"/>
]

<br> 

Had to move lots of data across networks to make workflows runs.

---

### To The Cloud: NeuroData 2016

Co-developed (shared code base) with the IARPA MICrONS [BOSS](https://api.theboss.io/)
- Post images from microscope to S3
- Process and share with AWS services
- Cloud-based interactive data analysis (Jupyter)



---

### Transformations in the Cloud

<br>

Adopt the [Render Service](https://github.com/saalfeldlab/render) from [Janelia](http://www.janelia.org)
- apply a lineage of image transformations on demand
- materialize any stage of image processing

.cbar[
[@troutmane](https://github.com/troutmane)
]


---
.left-column[
<img src="images/fullpm.png" style="height: 600px;"/>
]
.right-column[
NeuroDataViz can examine any stage of transformations
- ability to look at point match functions prior to elastic correction
<img src="images/zoompm.png" style="height: 300px;"/>
]

---
class: split-80

.column[
<img src="images/zoompm.png" style="height: 300px;"/>
]
.column[
### Visualizing Transformations
<img src="images/fullpm.png" style="height: 600px;"/>
]

---


### The NeuroData Storage Hierarchy
<br>

- 

.center[
<img src="images/ndcomplete.png" style="height: 400px;"/>
<!-- <img src="images/reshier.png" style="height: 250px;"/>
<img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Moore3d-step3.png" style="height: 250px;"/>
 -->
 ]


.cbar[
[@kunal](https://github.com/kunallillaney)
]

---

name: ramondb
layout: false

### Store: Shape Data Model
<br>

- Goal: general enough for many data types 
- Challenge: simple enough to understand
- Action: .y[ndramon]


.center[
<img src="images/ramon.png" style="height: 350px;"/>
]


.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]

---

### Store: Read Shapes 
<br>

- Goal: enable easy semantic queries
- Challenge: no standard "structured vocabulary"
- Action: .y[ramondb] stores object metadata


<br>

.center[
<img src="images/fig5_mitochondria.png" style="height: 250px;"/>
<img src="images/fig5_vesicles.png" style="height: 250px;"/>
]

<br>
.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]



---


<!-- ---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | [Discussion](#disc)]
 -->
---
name: explore
layout: false

### Explore: Images  

<br>

- Goal: google maps like interface to explore images
- Challenge: mobile speed
- Action: .y[ndviz] navigation



.center[
<img src="images/ndpaper-fig2a.png" style="width: 550px;"/>
]

.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://ix.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz/issues)
]

---

### Explore: Histograms


<br>

- Goal: explore histograms of very large volumes
- Challenge: cannot compute histograms in memory
- Action: .y[ndhist] 



.center[
<img src="images/explore-hist.png" style="width: 450px;"/>
]


.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://hx.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/histogram-explorer) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/histogram-explorer/issues)
]


---

### Explore: Shapes  

<br>

- Goal: dynamically overlay annotations
- Challenge: interactivity
- Action: .y[ndviz] add channel + query

<br>

.center[
<img src="images/ndpaper-fig2c.png" style="width: 700px;"/>
]

.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://ix.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz/issues)
]



---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | [Discussion](#disc)]


---
name: 2d
layout: false



### 2D Color/Intensity Correction

<br>

Automatically remove artifacts from imaging tiles seperately
- Distributed multi-grid Poisson solver

<br>

.center[
<img src="images/A_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
<img src="images/D_dmg_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
]
<br>


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/MyPapers/ToG10.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name: 3d

### 3D Color/Intensity Correction

<br>

Automatically remove 3D artifacts in serial sections
- Smooth system in gradient domain to normalize
- Add high-frequencies back in to preseve edges 



<br>

.center[
<img src="images/GDF2.png" alt="Drawing" style="width: 100%;"/>
]

---
name: 3d2

### 3D Color/Intensity Correction

<br>

Automatically remove 3D artifacts in serial sections
- Solve global Poisson system in gradient domain to normalize
- Add high-frequencies back in to preseve edges 

<br>
.center[
<iframe width="560" height="315" src="https://www.youtube.com/embed/TfUNmb5GwGw&showinfo=0" frameborder="0" allowfullscreen></iframe>
]


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://arxiv.org/pdf/1506.02079v1.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name:ndparse
### Analyze: Object Detection

<br>

- Goal: scalable object detection 
- Challenge: requires  labeling, training, & distributed computing
- Action: .y[ndparse] 


.center[
<img src="images/ndp_bock_truth_crop.png"    alt="Drawing" style="width: 340px;"/>
<img src="images/ndp_bock_detect_crop_circles.png"    alt="Drawing" style="width: 340px;"/>
]
<br>


.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndparse) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndparse/mbcd.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndparse/issues/new)
]





---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | _[Results](#applications)_  | [Discussion](#disc)]


---
name: applications
layout: false
class: middle, center

.center[
# Results
]


<!-- <br> -->

<!-- .center[
<img src="images/image_datasets.png" alt="Drawing" style="height: 150px;"/>
<img src="images/annotation_datasets.png" alt="Drawing" style="height: 150px;"/>

<br>

<img src="images/rob2.png"    alt="Drawing" style="height: 250px; "/>
<img src="images/3D.png"    alt="Drawing" style="height: 250px; "/>
]

add links
 -->

<!-- ---
name: applications

# Results

<br>

- [Image Datasets](#r_im)
- [Annotation Datasets](#r_anno)
- [Case Study 1](#r_cs1)
- [Case Study 2](#r_cs2)
 -->

---
name: r_im

## Image Datasets


.center[
<img src="images/image_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 10+ public datasets
- EM, AT, Ophys, XCT
- 100+ teravoxels
- All "reference" datasets


.cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i> Projects](http://neurodata.io/projects)
]

---
name: r_anno

## Annotation Datasets



.center[
<img src="images/annotation_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 5 different publications with volumetric annotations
- No skeleton annotations yet
- Volumetric required for training machine vision
- Annotations cross spatiotemporal scale: nano, micro, time-series


---
name: r_cs1

## Case Study #1 
#### Reproducible and Extensible Big Data Neuroscience


<br>

Statistical claims
1. [axons & dendrites](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim02_axons_and_dendrites.ipynb)
1. [synapses](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim3_synapses.ipynb)
1. [mitochondria](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim4_mitochondria.ipynb)
1. [spines](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim5_spines.ipynb)
1. [vesicles](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim6_vesicles.ipynb)
1. [connectivity](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim9_make_graph.ipynb)


---

## Case Study #1 
#### Reproducible and Extensible Big Data Neuroscience

<br>

[axons and dendrites](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim2_axons_and_dendrites.ipynb)
1. How many different neurons?
1. How many dendrites?
1. What fraction are spiny?
1. How many unmyelinated axons?
1. What fraction are excitatory?
1. How many spines?
1. How many axon branches?
1. What fraction of cellular volume is neuron?
1. What fraction of volume is cells?
1. Relative volume of axon vs. dendrite?
...


 .cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndpaper2016/case_study1.html)
Data: Kasthuri et al. (Cell) 2015
]




---
name: r_cs2

## Case Study #2 
#### Is synapse distribution uniform in space?


<br />

.center[
<img src="images/rob2.png"    alt="Drawing" style="width: 75%; "/>
]

Detecting ~11.6 million synapses from the [bock11](http://openconnecto.me/bock11) dataset

???

timings

---
name: r_anal
class: center, middle

<!-- ### Case Study #2
#### Is synapse distribution uniform in space?
 -->

<!-- 
.pull-left[
<br />
1. find all synapses
1. Mask out regions that cannot have synapses
1. Partition volume into cuboids
2. Count # of elements / cuboid
3. Normalize by volume of cuboid not masked
4. Plot normalized density in 3D scatter plot
5. Plot marginal densities
6. Report p-value
] -->


<img src="images/3D.png"    alt="Drawing" style="width: 550px; "/>
<img src="images/2Dproj.png"    alt="Drawing" style="width: 550px; "/>


 .cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndpaper2016/case_study2.html)
Data: Bock et al. (Nature) 2011
]





---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | _[Discussion](#disc)_]

---
name: disc
class: middle, center
layout: false

# Discussion

---



### Open Science Contributions


- Reference EM and other datasets
- Reference annotations (crucial for training machine learning)
- Reference pipelines for operating on such data
- Web-services for data access
- Comprehensive cloud computing platform

--

<br />

### Implications: it is now easier to


- Answer questions that require scale
- Engage complementary expertise
- Reproduce and extend results


--

### Coming soon



- [ndio](http://docs.neurodata.io/nddocs/ndio/) python API 
- More public datasets: CLARITY, ExM, XCM, MRI, Ophys, etc. 
- More Web-services: processing each data modality
<!-- , including 
  - [Volume reconstruction](http://abria.github.io/TeraStitcher/) 
  - Color correction ([dmg](https://github.com/mkazhdan/DMG)) 
 & [gdf](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/) 
  - [Atlas registration](https://github.com/neurodata/ndreg) (ndreg)
  - [Ontological object detection](https://github.com/neurodata/ndparse) (ndparse)
  - [Ophys Spike detection](https://github.com/jovo/oopsi) (oopsi)
  - Ephys Spike Detection: [batch](https://github.com/jovo/spike-sorting), [online](https://github.com/decarlson/opass)
  - [MRI to Graphs](http://m2g.io/) (m2g) -->
<!-- - Web-services for all model steps -->
<!-- , including:
  - Shapes
  - Graphs
  - Matrices  -->



---


### Related Work


- [CATMAID](http://catmaid.readthedocs.org/en/stable/)
- [Neurodata Without Borders](http://nwb.org/)
- [Keller Lab Block File Format](http://www.nature.com/nprot/journal/v10/n11/abs/nprot.2015.111.html)


--


### Further Lowering the Barrier to Entry


- Put it all together
- Apply to other domains & questions
- We work together!

--

### References



1. Burns B et al. [The Open Connectome Project Data Cluster: Scalaballe Analysis and Vision for High-Throughput Neuroscience](http://arxiv.org/abs/1306.3543).  Scientific and Statistical Database Management (SSDBM), 2013.

1. Burns B, Vogelstein JT, Szalay AS. [From Cosmos to Connectomes: the Evolution of Data-Intensive Science](http://www.sciencedirect.com/science/article/pii/S0896627314007466). Neuron, 2015.


---
name: fam
layout: false
class:  center

# NeuroData Family




.center[
|   |   | |
| :--- | :--- | :--- |
| .r[Collect] | | .r[Clay Reid, Davi Bock, Jeff Licthman, Bobb Kasthuri, Karl Deisseroth, Raju Tomer, Li Ye, Ailey Crow, Ed Boyden, Mike Milham, Cameron Craddock, Stephen Smith, Forrest Collman, Kristen Harris, Scott Emmons, Dan Bumbarger, Mitya Chklovskii, Nikhil Bhatla, Nelson Spruston, Erik Bloss]
| .orange[Store] | | .orange[Randal Burns, Eric Perlman, Kunal Lillaney, Priya Manavalan, Alex Eusman]
| .ye[Explore] | | .ye[Alex Baden,  Ivan Kuznetsov, David Marchette, Leo Duan, Albert Lee]
| .g[Analyze] | &nbsp;&nbsp;&nbsp;&nbsp; | .g[Mike Miller, Nicholas Charon, Misha Kazhdan, Jordan Matelsky, Kwame Kutten, Greg Kiar, Eric Bridgeford, Greg Hager, Will Gray Roncal, Mark Chevillet,  Dean Kleissas, R. Jacob Vogelstein, Guillermo Sapiro, Anish Simhal, Konrad Kording, Eva Dyer]
| .blue[Model] | | .blue[Joshua T. Vogelstein, Carey Priebe, Dan Naiman,  Tyler Tomita, Youngser Park, Jesse L. Patsolic, Leo Duan, Cencheng Shen, Ivan Kuznetsov]
| .purple[Graphs] | | .purple[Da Zheng, Disa Mhembere, Vince Lyzinski, Avanti Athreya, Daniel Sussman, Shangsi Wang, Runze Tang, Minh Tang]
]




---
class:   middle, center


# Questions?

<!-- ### Funding &nbsp;&nbsp;&nbsp;&nbsp;   -->

<!-- <br /> -->

_____

Funding


NIH: {CRCNS, BRAIN, TRA}

NSF:  BIGDATA

DARPA: {XDATA,GRAPHS,SIMPLEX}

IARPA: MICrONS

____


w: [neurodata.io](http://neurodata.io)

d: [docs.neurodata.io](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io)


<!-- ____ -->


<!-- [more slides](http://docs.neurodata.io/ndintro/more.html) -->





    </textarea>
    <script src="remark-latest.min.js" type="text/javascript">
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();

      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });

      MathJax.Hub.Configured();

var slideshow = remark.create({
  // Set the slideshow display ratio
  // Default: '4:3'
  // Alternatives: '16:9', ...
  ratio: '4:3',

  // Navigation options
  navigation: {
    // Enable or disable navigating using scroll
    // Default: true
    // Alternatives: false
    scroll: true,

    // Enable or disable navigation using touch
    // Default: true
    // Alternatives: false
    touch: true,

    // Enable or disable navigation using click
    // Default: false
    // Alternatives: true
    click: false
  },

  // Customize slide number label, either using a format string..
  // slideNumberFormat: 'Slide %current% of %total%',
  // .. or by using a format function
  slideNumberFormat: function (current, total) {
    return  current + ' of ' + total;
  },

  // Enable or disable counting of incremental slides in the slide counting
  countIncrementalSlides: false
}); 

    </script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
  </body>
</html>
