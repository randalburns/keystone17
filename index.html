<!DOCTYPE html>
<html>
  <head>
    <!-- <link href="https://file.myfontastic.com/n6vo44Re5QaWo8oCKShBs7/icons.css" rel="stylesheet"> -->

    <!-- bootstrap icons -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- font awesome icons -->
    <link rel="stylesheet" href="css/font-awesome-4.6.3/css/font-awesome.min.css">
    
    <!-- google web fonts -->
    <!-- <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"> -->

    <!-- bower:css -->
    <!-- <link rel="stylesheet" href="/content/themes/jhu_id/bower_components/normalize-css/normalize.css"> -->
    <link rel="stylesheet" href="fonts/gentona/gentona.css">
    <link rel="stylesheet" href="fonts/titling-gothic/titling-gothic.css">
    <link rel="stylesheet" href="fonts/quadon/quadon.css">
    <link rel="stylesheet" href="fonts/arnhem/arnhem.css">
    <!-- endbower -->

    <title>NeuroData Intro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      /*@import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);*/
      /*@import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);*/
      /*@import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);*/
      /*@import url(http://fonts.googleapis.com/css?family=Varela+Round:regular,italic,bold,bolditalic);*/
      /*@import url(http://fonts.googleapis.com/css?family=Raleway:regular,italic,bold,bolditalic);*/

      body {
        font-family: 'gentona'; /* Varela Round */
        font-size: 1.6em;
      }
      /*      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
      }      */
      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
        font-weight: 400;
        margin-bottom: 0;
        color: #d5ad6d;
/*        color:  #D5AD6D; /*if no support for background-clip*/
  
        /*background: -webkit-linear-gradient(transparent, transparent),*/
             /*-webkit-linear-gradient(top, rgba(213,173,109,1) 0%, rgba(213,173,109,1) 26%, rgba(226,186,120,1) 35%, rgba(163,126,67,1) 45%, rgba(145,112,59,1) 61%, rgba(213,173,109,1) 100%);*/
        /*background: -o-linear-gradient(transparent, transparent);*/
  /*-webkit-background-clip: text;*/
  /*-webkit-text-fill-color: transparent;*/

      }
      .remark-slide-content {
        font-size: 1.5em;
        background: #272822;
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */
        background: -webkit-radial-gradient(circle, #272822, #15120e, black); /* Safari */
        background: -o-radial-gradient(circle, #272822, #15120e, black); /* Opera 11.6 to 12.0 */
        background: -moz-radial-gradient(circle, #272822, #15120e, black); /* Firefox 3.6 to 15 */
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */

        color: #ebd8b9; /*#f4e9d8;*/ /*#debe8b;*/ /*#6dd5ad;*/ /*rgba(213,173,109,1);*/ /*rgba(163,126,67,1);*/ /*rgba(226,186,120,1);*/ /*rgba(213,173,109,1);*/ /*#6dd5ad;*/
        /*background: #3B263C;*/
  /*        color:  #FFFF00; /*#DDA0DD;*/  /*#A565D6;*/ /* #DF9BFF;*/ /*#FFFF00;*/*/
      }

      h1, h2, h3, h4 {
        text-align: center;
        /*text-shadow: 2px 2px gray; /*#ff0000;*/*/
      }

      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .remark-slide-content h4 { font-size: 1.4em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .navbar {
        position: absolute;
        float: center;
        top: 0em;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .navbar a {
        color: #A7A7A7;
      }
      .bbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .bbar a {
        color: #A7A7A7;
      }
      .cbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        /*color: #A7A7A7;*/
        color: #bdbcbc;
      }
      .cbar a{
       color: #bdbcbc; 
      }

      .btn {
        background: #424242;
        height: 2em;
      }
      li p { line-height: 1.25em; }
      .r { color: #fa0000; }
      .w {color: white;}
      .ye { color: #FFFF00; }
      .y { color: #fcfaf6; }
      .pink { color: #FF87F3;}
      .orange { color: #FFA500;}
      .g { color: #00CC00; }
      .blue { color: #75E9FF;}
      .purple { color: #A149A9;}
      .large { font-size: 2em; }
      .black { color: black; background-color: white;}
      a, a > code {
        color:  rgb(249, 38, 114); 
        color: white; 
        color: #bdbcbc; 
        /*color: #b1b1b1;*/
        text-decoration: none; /*underline*/
      }

      a:hover {
        color: white;
      }


      code {
        background: #424242;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
/*      .pull-left {
        float: left;
        width: 47%;
      }*/
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .small {
        font-size: 0.8em;
      }
/*      .pull-right {
        float: right;
        width: 47%;
      }*/
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .bottom {
        position: absolute;
        bottom: 35px;
        left: 13px;
        font-family: 'Yanone Kaffeesatz';
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: white;
        color: white;
        text-shadow: 0 0 20px #333;
      }
      .inverse p {
        color: white;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }
      #frame { zoom: 0.75; -moz-transform: scale(0.75); -moz-transform-origin: 0 0; }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-child {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 50%;
      }
      .task {
        float: right;
        font-size: 0.9em;
        padding-top: 0.6em;
      }

  }
    </style>
  </head>
  <body onload="var slideshow = remark.create();">
    <textarea id="source">



class: center, middle

name:opening

# [NeuroData](http://neurodata.io):
### Enabling Terascale Neuroscience for Everyone

<!-- ### Joshua T. Vogelstein -->
<!-- ### {[BME](http://bme.jhu.edu),[ICM](http://icm.jhu.edu),[CIS](http://cis.jhu.edu),[Kavli](http://kndi.jhu.edu)}@[jhu](http://jhu.edu) -->

<!-- #### e: [jovo@jhu.edu](mailto:jovo@jhu.edu) | w:  -->
<!-- ### [NeuroData.io](http://neurodata.io) -->




<br>
<!-- [prof joshua t. vogelstein](http://jovo.me) -->


<br>

.center[
presented by, Joshua T. Vogelstein
<br>
{[bme](http://www.bme.jhu.edu/),[icm](http://icm.jhu.edu/),[cis](http://cis.jhu.edu/),[idies](http://idies.jhu.edu/),kavli,[cs](http://engineering.jhu.edu/computer-science/), [ams](http://engineering.jhu.edu/ams/), [neuro](http://neuroscience.jhu.edu/)}@[jhu](https://www.jhu.edu/)
<br>
please ask questions: [support@neurodata.io](mailto:support at neurodata dot io)!
<br>
these slides: <http://docs.neurodata.io/ndintro>

]



---

# Big Scientific Data

<br>

.pull-left[
- molecular genomics (1D)
]
.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/A_genome_alignment_of_eight_Yersinia_isolates.png/380px-A_genome_alignment_of_eight_Yersinia_isolates.png" alt="Drawing" style="width: 400px;"/>]


---


# Big Scientific Data

<br>

.pull-left[
- molecular genomics (1D)
- cosmology (2D)
]

.pull-right[
<img src="https://upload.wikimedia.org/wikipedia/commons/3/3c/Ilc_9yr_moll4096.png" alt="Drawing" style="width: 400px;"/>]


---


# Big Scientific Data

<br>

.pull-left[
- molecular genomics (1D)
- cosmology (2D)
- Neuroscience! (3D+)
]

.pull-right[
<img src="http://www.nature.com/neuro/journal/v17/n11/images/nn.3839-F1.jpg
" alt="Drawing" style="width: 400px;"/>]


---
class: center, middle
<!-- https://openwiki.janelia.org/wiki/download/attachments/34505478/Image%201%20-%20Medulla%20EM%20Stack%20-%20Final.jpg?version=1&modificationDate=1375908720000&api=v2 -->


<!-- ### Opportunity: Big Neuro Data -->

<!-- .center[6 panel nd website figure] -->

<img src="images/oppo/em.jpg"/>
<img src="images/oppo/at.png"/>
<img src="images/oppo/clarity.jpg"/>
<img src="images/oppo/xbrain.png"/>
<img src="images/oppo/fibers.jpg"/>
<img src="images/oppo/mri.png"/>






---


## Challenge #1

.center[
<iframe width="600" height="420" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]


Goal: Enable generating and confirming anatomical hypothesis using simple tools, in a reproducible and extensible fashion.




---

## Challenge #2




.center[
<iframe width="720" height="400" src="https://www.youtube.com/embed/dS_ONoUrptg?rel=0" frameborder="0" allowfullscreen></iframe>


<br>
Goal: What is the spatial distribution of synapses?

]






---
class: center

## [NeuroData](http://neurodata.io) 6 steps to discovery

<img src="images/circle6.png" alt="Drawing" style="width: 600px;"/>
<!-- <img src="https://github.com/neurodata/ndpaper/raw/master/figure0.png" alt="Drawing" style="width: 700px;"/> -->

<br />

<!-- --

.left-pull[
- An cloud deployed ecosystem for big data neuroscience
- Currently hosts 10+ public datasets, another 20+ private datasets
- Total # of terabytes used: ~250 
- Enables universal accessibility, reproducibility, and extensibility
- Revealed novel spatial synapse patterns
- Free and open source software (FOSS), and free and open access data (FOAD)
]
 -->

---
name: applications
layout: false
class: middle, center

.center[
# Methods
]


---
layout: false
class: middle, center
<!-- .bbar[ [Intro](#intro) | _[Methods](#methods)_ | [Results](#applications)  | [Discussion](#disc)] -->
<!-- --- -->



<img src="images/fig0.png" alt="Drawing" style="width: 800px;"/>


---
name:store

### Store
<br>

- Goal: eliminate read/write bottlenecks
- Challenge: accessing a file takes time, data are big
- Action: .y[ndbackend] infrastructure



.center[
<img src="images/ndcomplete.png" style="height: 400px;"/>
<!-- <img src="images/reshier.png" style="height: 250px;"/>
<img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Moore3d-step3.png" style="height: 250px;"/>
 -->
 ]


.cbar[
[@kunal](https://github.com/kunallillaney)
]

<!-- [Code](https://github.com/neurodata/ndstore) 
| [Docs](http://docs.neurodata.io/ndstore/sphinx/console.html) 
| [API](http://docs.neurodata.io/ndstore/) 
| [Manuscript](http://arxiv.org/abs/1306.3543) 
| [Setup](https://github.com/neurodata/ndstore/tree/master/setup) 
| [<span class="images/issue.png"></span>](https://github.com/neurodata/ndstore/tree/master/setup)
<a href="#"><span class="glyphicon glyphicon-file"></span></a>
<a href="#"><span class="glyphicon glyphicon-book"></span></a>
<a href="#"><span class="glyphicon glyphicon-exclamation-sign"></span></a>
[<span class="glyphicon glyphicon-exclamation-sign"></span>](https://github.com/neurodata/ndstore/tree/master/setup) -->


---
layout: false
class: left


### Store: Image Data Model
<br>

- Goal: general enough for many data types 
- Challenge: simple enough to understand
- Action: .y[nddatamodel]

<br>

.center[
<img src="images/datamodel_simple.png" style="height: 300px;"/>
]


.cbar[
[@kunal](https://github.com/kunallillaney) 
]


---

### Store: Write Volumes
<br>

- Goal: write faster than acquire
- Challenge: data stored as images, streamed quickly
- Action: .y[ndstore] spatial database

<br>

.center[
<!-- <img src="images/ndpaper-fig1a.png" style="height: 200px;"/> -->
<img src="images/ndpaper-fig1b.png" style="height: 300px;"/>
]

.cbar[
[@kunal](https://github.com/kunallillaney): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/ndstore/sphinx/console.html)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/issues/new)
]


---

### Store: Read Volumes
<br>

- Goal: read volumes for machine vision
- Challenge: data stored as images
- Action: .y[ndstore] spatial database

<br>

.center[
<img src="images/ndpaper-fig1a.png" style="height: 300px;"/>
<!-- <img src="images/ndpaper-fig1b.png" style="height: 200px;"/> -->
]

.cbar[
[@kunal](https://github.com/kunallillaney): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/ndstore/sphinx/console.html)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/issues/new)
]



---

### Store: Read Tiles
<br>

- Goal: visualize @ video rates for mobile
- Challenge: data stored in cubes
- Action: .y[ndtilecache] content distribution network


<br>

.center[
<img src="images/ndpaper-fig1c.png" style="height: 300px;"/>
]



.cbar[
[@kunal](https://github.com/kunallillaney): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndtilecache)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/ndstore/api/tile_api.html)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndtilecache/issues/new)
]


---
name: ramondb
layout: false

### Store: Shape Data Model
<br>

- Goal: general enough for many data types 
- Challenge: simple enough to understand
- Action: .y[ndramon]


.center[
<img src="images/ramon.png" style="height: 350px;"/>
]


.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]

---

### Store: Read Shapes 
<br>

- Goal: enable easy semantic queries
- Challenge: no standard "structured vocabulary"
- Action: .y[ramondb] stores object metadata


<br>

.center[
<img src="images/fig5_mitochondria.png" style="height: 250px;"/>
<img src="images/fig5_vesicles.png" style="height: 250px;"/>
]

<br>
.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]



---

### Store: Write Shapes 
<br>

- Goal: write annotations with object-level metadata fast
- Challenge: many small files
- Action: .y[ndblaze] assembles transparently in RAM


.center[
<img src="images/ndpaper-fig1d.png" style="width: 600px;"/>
]



.cbar[
[@kunal](https://github.com/kunallillaney): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndblaze)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndblaze/issues/new)
]


<!-- ---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | [Discussion](#disc)]
 -->
---
name: explore
layout: false

### Explore: Images  

<br>

- Goal: google maps like interface to explore images
- Challenge: mobile speed
- Action: .y[ndviz] navigation



.center[
<img src="images/ndpaper-fig2a.png" style="width: 550px;"/>
]

.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://ix.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz/issues)
]

---

### Explore: Histograms


<br>

- Goal: explore histograms of very large volumes
- Challenge: cannot compute histograms in memory
- Action: .y[ndhist] 



.center[
<img src="images/explore-hist.png" style="width: 450px;"/>
]


.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://hx.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/histogram-explorer) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/histogram-explorer/issues)
]


---

### Explore: Shapes  

<br>

- Goal: dynamically overlay annotations
- Challenge: interactivity
- Action: .y[ndviz] add channel + query

<br>

.center[
<img src="images/ndpaper-fig2c.png" style="width: 700px;"/>
]

.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://ix.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz/issues)
]



---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | [Discussion](#disc)]


---
name: 2d
layout: false



### Analyze: 2D Correction

<br>

- Goal: auto remove 2D histogram artifacts 
- Challenge: signal & noise overlap, data are big
- Action: .y[distributed multi-grid] (dmg)

<br>

.center[
<img src="images/A_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
<img src="images/D_dmg_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
]
<br>


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/MyPapers/ToG10.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name: 3d

### Analyze: 3D Correction

<br>

- Goal: auto remove 3D histogram artifacts 
- Challenge: data are bigger
- Action: .y[gradient domain fusion] (gdf)

<br>

.center[
<img src="images/GDF2.png" alt="Drawing" style="width: 100%;"/>
]
<br>


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://arxiv.org/pdf/1506.02079v1.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name:ndparse
### Analyze: Object Detection

<br>

- Goal: scalable object detection 
- Challenge: requires  labeling, training, & distributed computing
- Action: .y[ndparse] 


.center[
<img src="images/ndp_bock_truth_crop.png"    alt="Drawing" style="width: 340px;"/>
<img src="images/ndp_bock_detect_crop_circles.png"    alt="Drawing" style="width: 340px;"/>
]
<br>


.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndparse) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndparse/mbcd.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndparse/issues/new)
]





---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | _[Results](#applications)_  | [Discussion](#disc)]


---
name: applications
layout: false
class: middle, center

.center[
# Results
]


<!-- <br> -->

<!-- .center[
<img src="images/image_datasets.png" alt="Drawing" style="height: 150px;"/>
<img src="images/annotation_datasets.png" alt="Drawing" style="height: 150px;"/>

<br>

<img src="images/rob2.png"    alt="Drawing" style="height: 250px; "/>
<img src="images/3D.png"    alt="Drawing" style="height: 250px; "/>
]

add links
 -->

<!-- ---
name: applications

# Results

<br>

- [Image Datasets](#r_im)
- [Annotation Datasets](#r_anno)
- [Case Study 1](#r_cs1)
- [Case Study 2](#r_cs2)
 -->

---
name: r_im

## Image Datasets


.center[
<img src="images/image_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 10+ public datasets
- EM, AT, Ophys, XCT
- 100+ teravoxels
- All "reference" datasets


.cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i> Projects](http://neurodata.io/projects)
]

---
name: r_anno

## Annotation Datasets



.center[
<img src="images/annotation_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 5 different publications with volumetric annotations
- No skeleton annotations yet
- Volumetric required for training machine vision
- Annotations cross spatiotemporal scale: nano, micro, time-series


---
name: r_cs1

## Case Study #1 
#### Reproducible and Extensible Big Data Neuroscience


<br>

Statistical claims
1. [axons & dendrites](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim02_axons_and_dendrites.ipynb)
1. [synapses](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim3_synapses.ipynb)
1. [mitochondria](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim4_mitochondria.ipynb)
1. [spines](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim5_spines.ipynb)
1. [vesicles](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim6_vesicles.ipynb)
1. [connectivity](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim9_make_graph.ipynb)


---

## Case Study #1 
#### Reproducible and Extensible Big Data Neuroscience

<br>

[axons and dendrites](https://github.com/neurodata/kasthuri2015/blob/master/claims/claim2_axons_and_dendrites.ipynb)
1. How many different neurons?
1. How many dendrites?
1. What fraction are spiny?
1. How many unmyelinated axons?
1. What fraction are excitatory?
1. How many spines?
1. How many axon branches?
1. What fraction of cellular volume is neuron?
1. What fraction of volume is cells?
1. Relative volume of axon vs. dendrite?
...


 .cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndpaper2016/case_study1.html)
Data: Kasthuri et al. (Cell) 2015
]




---
name: r_cs2

## Case Study #2 
#### Is synapse distribution uniform in space?


<br />

.center[
<img src="images/rob2.png"    alt="Drawing" style="width: 75%; "/>
]

Detecting ~11.6 million synapses from the [bock11](http://openconnecto.me/bock11) dataset

???

timings

---
name: r_anal
class: center, middle

<!-- ### Case Study #2
#### Is synapse distribution uniform in space?
 -->

<!-- 
.pull-left[
<br />
1. find all synapses
1. Mask out regions that cannot have synapses
1. Partition volume into cuboids
2. Count # of elements / cuboid
3. Normalize by volume of cuboid not masked
4. Plot normalized density in 3D scatter plot
5. Plot marginal densities
6. Report p-value
] -->


<img src="images/3D.png"    alt="Drawing" style="width: 550px; "/>
<img src="images/2Dproj.png"    alt="Drawing" style="width: 550px; "/>


 .cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndpaper2016/case_study2.html)
Data: Bock et al. (Nature) 2011
]





---
layout: true
.bbar[ [Intro](#intro) | [Methods](#methods) | [Results](#applications)  | _[Discussion](#disc)_]

---
name: disc
class: middle, center
layout: false

# Discussion

---



### Open Science Contributions


- Reference EM and other datasets
- Reference annotations (crucial for training machine learning)
- Reference pipelines for operating on such data
- Web-services for data access
- Comprehensive cloud computing platform

--

<br />

### Implications: it is now easier to


- Answer questions that require scale
- Engage complementary expertise
- Reproduce and extend results


--

### Coming soon



- [ndio](http://docs.neurodata.io/nddocs/ndio/) python API 
- More public datasets: CLARITY, ExM, XCM, MRI, Ophys, etc. 
- More Web-services: processing each data modality
<!-- , including 
  - [Volume reconstruction](http://abria.github.io/TeraStitcher/) 
  - Color correction ([dmg](https://github.com/mkazhdan/DMG)) 
 & [gdf](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/) 
  - [Atlas registration](https://github.com/neurodata/ndreg) (ndreg)
  - [Ontological object detection](https://github.com/neurodata/ndparse) (ndparse)
  - [Ophys Spike detection](https://github.com/jovo/oopsi) (oopsi)
  - Ephys Spike Detection: [batch](https://github.com/jovo/spike-sorting), [online](https://github.com/decarlson/opass)
  - [MRI to Graphs](http://m2g.io/) (m2g) -->
<!-- - Web-services for all model steps -->
<!-- , including:
  - Shapes
  - Graphs
  - Matrices  -->



---


### Related Work


- [CATMAID](http://catmaid.readthedocs.org/en/stable/)
- [Neurodata Without Borders](http://nwb.org/)
- [Keller Lab Block File Format](http://www.nature.com/nprot/journal/v10/n11/abs/nprot.2015.111.html)


--


### Further Lowering the Barrier to Entry


- Put it all together
- Apply to other domains & questions
- We work together!

--

### References



1. Burns B et al. [The Open Connectome Project Data Cluster: Scalaballe Analysis and Vision for High-Throughput Neuroscience](http://arxiv.org/abs/1306.3543).  Scientific and Statistical Database Management (SSDBM), 2013.

1. Burns B, Vogelstein JT, Szalay AS. [From Cosmos to Connectomes: the Evolution of Data-Intensive Science](http://www.sciencedirect.com/science/article/pii/S0896627314007466). Neuron, 2015.


---
name: fam
layout: false
class:  center

# NeuroData Family




.center[
|   |   | |
| :--- | :--- | :--- |
| .r[Collect] | | .r[Clay Reid, Davi Bock, Jeff Licthman, Bobb Kasthuri, Karl Deisseroth, Raju Tomer, Li Ye, Ailey Crow, Ed Boyden, Mike Milham, Cameron Craddock, Stephen Smith, Forrest Collman, Kristen Harris, Scott Emmons, Dan Bumbarger, Mitya Chklovskii, Nikhil Bhatla, Nelson Spruston, Erik Bloss]
| .orange[Store] | | .orange[Randal Burns, Eric Perlman, Kunal Lillaney, Priya Manavalan, Alex Eusman]
| .ye[Explore] | | .ye[Alex Baden,  Ivan Kuznetsov, David Marchette, Leo Duan, Albert Lee]
| .g[Analyze] | &nbsp;&nbsp;&nbsp;&nbsp; | .g[Mike Miller, Nicholas Charon, Misha Kazhdan, Jordan Matelsky, Kwame Kutten, Greg Kiar, Eric Bridgeford, Greg Hager, Will Gray Roncal, Mark Chevillet,  Dean Kleissas, R. Jacob Vogelstein, Guillermo Sapiro, Anish Simhal, Konrad Kording, Eva Dyer]
| .blue[Model] | | .blue[Joshua T. Vogelstein, Carey Priebe, Dan Naiman,  Tyler Tomita, Youngser Park, Jesse L. Patsolic, Leo Duan, Cencheng Shen, Ivan Kuznetsov]
| .purple[Graphs] | | .purple[Da Zheng, Disa Mhembere, Vince Lyzinski, Avanti Athreya, Daniel Sussman, Shangsi Wang, Runze Tang, Minh Tang]
| .pink[Love] | | .pink[Yummy, Family, Friends, Earth, Universe, Multiverse?]
]




---
class:   middle, center


# Questions?

<!-- ### Funding &nbsp;&nbsp;&nbsp;&nbsp;   -->

<!-- <br /> -->

_____

Funding


NIH: {CRCNS, BRAINI, TRA}

NSF:  BIGDATA

DARPA: {XDATA,GRAPHS,SIMPLEX}

IARPA: MICrONS

____


w: [neurodata.io](http://neurodata.io)

d: [docs.neurodata.io](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io)


<!-- ____ -->


<!-- [more slides](http://docs.neurodata.io/ndintro/more.html) -->





    </textarea>
    <script src="remark-latest.min.js" type="text/javascript">
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();

      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });

      MathJax.Hub.Configured();

var slideshow = remark.create({
  // Set the slideshow display ratio
  // Default: '4:3'
  // Alternatives: '16:9', ...
  ratio: '4:3',

  // Navigation options
  navigation: {
    // Enable or disable navigating using scroll
    // Default: true
    // Alternatives: false
    scroll: true,

    // Enable or disable navigation using touch
    // Default: true
    // Alternatives: false
    touch: true,

    // Enable or disable navigation using click
    // Default: false
    // Alternatives: true
    click: false
  },

  // Customize slide number label, either using a format string..
  // slideNumberFormat: 'Slide %current% of %total%',
  // .. or by using a format function
  slideNumberFormat: function (current, total) {
    return  current + ' of ' + total;
  },

  // Enable or disable counting of incremental slides in the slide counting
  countIncrementalSlides: false
}); 

    </script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
  </body>
</html>
