<!DOCTYPE html>
<html>
  <head>
    <!-- <link href="https://file.myfontastic.com/n6vo44Re5QaWo8oCKShBs7/icons.css" rel="stylesheet"> -->

    <!-- bootstrap icons -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- font awesome icons -->
    <link rel="stylesheet" href="css/font-awesome-4.6.3/css/font-awesome.min.css">
    
    <!-- google web fonts -->
    <!-- <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"> -->

    <!-- bower:css -->
    <!-- <link rel="stylesheet" href="/content/themes/jhu_id/bower_components/normalize-css/normalize.css"> -->
    <link rel="stylesheet" href="fonts/gentona/gentona.css">
    <link rel="stylesheet" href="fonts/titling-gothic/titling-gothic.css">
    <link rel="stylesheet" href="fonts/quadon/quadon.css">
    <link rel="stylesheet" href="fonts/arnhem/arnhem.css">
    <!-- endbower -->

    <title>NeuroData Intro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">

      body {
        font-family: 'gentona'; /* Varela Round */
        font-size: 1.6em;
      }
      /*      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
      }      */
      h1, h2, h3, h4, h5, h6 {
        font-family: 'quadon';
        font-weight: 400;
        margin-bottom: 0;
        color: #d5ad6d;
/*        color:  #D5AD6D; /*if no support for background-clip*/
  
        /*background: -webkit-linear-gradient(transparent, transparent),*/
             /*-webkit-linear-gradient(top, rgba(213,173,109,1) 0%, rgba(213,173,109,1) 26%, rgba(226,186,120,1) 35%, rgba(163,126,67,1) 45%, rgba(145,112,59,1) 61%, rgba(213,173,109,1) 100%);*/
        /*background: -o-linear-gradient(transparent, transparent);*/
  /*-webkit-background-clip: text;*/
  /*-webkit-text-fill-color: transparent;*/

      }
      .remark-slide-content {
        font-size: 1.5em;
        background: #272822;
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */
        background: -webkit-radial-gradient(circle, #272822, #15120e, black); /* Safari */
        background: -o-radial-gradient(circle, #272822, #15120e, black); /* Opera 11.6 to 12.0 */
        background: -moz-radial-gradient(circle, #272822, #15120e, black); /* Firefox 3.6 to 15 */
        background: radial-gradient(circle, #272822, #15120e, black); /* Standard syntax */

        color: #ebd8b9; /*#f4e9d8;*/ /*#debe8b;*/ /*#6dd5ad;*/ /*rgba(213,173,109,1);*/ /*rgba(163,126,67,1);*/ /*rgba(226,186,120,1);*/ /*rgba(213,173,109,1);*/ /*#6dd5ad;*/
        /*background: #3B263C;*/
  /*        color:  #FFFF00; /*#DDA0DD;*/  /*#A565D6;*/ /* #DF9BFF;*/ /*#FFFF00;*/*/
      }

      h1, h2, h3, h4 {
        text-align: center;
        /*text-shadow: 2px 2px gray; /*#ff0000;*/*/
      }

      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .remark-slide-content h4 { font-size: 1.4em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .navbar {
        position: absolute;
        float: center;
        top: 0em;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .navbar a {
        color: #A7A7A7;
      }
      .bbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        color: #A7A7A7;
      }
      .bbar a {
        color: #A7A7A7;
      }
      .cbar {
        position: absolute;
        bottom: 13px;
        left: 13px;
        font-family: 'titling-gothic';  /* Yanone Kaffeesatz */
        font-weight: 200;
        /*color: #A7A7A7;*/
        color: #bdbcbc;
      }
      .cbar a{
       color: #bdbcbc; 
      }

      .btn {
        background: #424242;
        height: 2em;
      }
      li p { line-height: 1.25em; }
      .r { color: #fa0000; }
      .w {color: white;}
      .ye { color: #FFFF00; }
      .y { color: #fcfaf6; }
      .pink { color: #FF87F3;}
      .orange { color: #FFA500;}
      .g { color: #00CC00; }
      .blue { color: #75E9FF;}
      .purple { color: #A149A9;}
      .large { font-size: 2em; }
      .black { color: black; background-color: white;}
      a, a > code {
        color:  rgb(249, 38, 114); 
        color: white; 
        color: #bdbcbc; 
        /*color: #b1b1b1;*/
        text-decoration: none; /*underline*/
      }

      a:hover {
        color: white;
      }


      code {
        background: #424242;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
/*      .pull-left {
        float: left;
        width: 47%;
      }*/
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .center {
        margin: auto;
        width: 100%;
        padding: 10px;
      }
      .small {
        font-size: 0.8em;
      }
/*      .pull-right {
        float: right;
        width: 47%;
      }*/
      .pull-bottom {
        position: absolute;
        bottom: 0;
      }
      .bottom {
        position: absolute;
        bottom: 35px;
        left: 13px;
        font-family: 'Yanone Kaffeesatz';
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: white;
        color: white;
        text-shadow: 0 0 20px #333;
      }
      .inverse p {
        color: white;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }
      #frame { zoom: 0.75; -moz-transform: scale(0.75); -moz-transform-origin: 0 0; }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

.column:first-of-type {float:left}
.column:last-of-type {float:right}

.split-20 .column:first-of-type {width: 20%}
.split-20 .column:last-of-type {width: 80%}
.split-30 .column:first-of-type {width: 30%}
.split-30 .column:last-of-type {width: 70%}
.split-40 .column:first-of-type {width: 40%}
.split-40 .column:last-of-type {width: 60%}
.split-50 .column:first-of-type {width: 50%}
.split-50 .column:last-of-type {width: 50%}
.split-60 .column:first-of-type {width: 60%}
.split-60 .column:last-of-type {width: 40%}
.split-70 .column:first-of-type {width: 70%}
.split-70 .column:last-of-type {width: 30%}
.split-80 .column:first-of-type {width: 80%}
.split-80 .column:last-of-type {width: 20%}

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-child {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      br {
        line-height: 30%;
      }
      .task {
        float: right;
        font-size: 0.9em;
        padding-top: 0.6em;
      }


    </style>
  </head>
  <body onload="var slideshow = remark.create();">
    <textarea id="source">



class: center, middle

name:opening

## Data-Intensive Applications:
## [The OpenConnectome Project](http://openconnecto.me)
### A [NeuroData](http://neurodata.io) Project


<br>

.center[
Randal Burns
<br>
{[CS](http://www.cs.jhu.edu/),[KNDI](http://idies.jhu.edu/),[IDIES](http://idies.jhu.edu/)}@[JHU](https://www.jhu.edu/)
<br>
please ask questions: [support@neurodata.io](mailto:support at neurodata dot io)
<br>
these slides: <http://docs.neurodata.io/keystone.ocp17>

]


---
class: center, middle

### NeuroData Data


<!-- https://openwiki.janelia.org/wiki/download/attachments/34505478/Image%201%20-%20Medulla%20EM%20Stack%20-%20Final.jpg?version=1&modificationDate=1375908720000&api=v2 -->


<!-- ### Opportunity: Big Neuro Data -->

<!-- .center[6 panel nd website figure] -->


<img src="images/oppo/em.jpg"/>
<img src="images/oppo/at.png"/>
<img src="images/oppo/clarity.jpg"/>
<img src="images/oppo/xbrain.png"/>
<img src="images/oppo/fibers.jpg"/>
<img src="images/oppo/mri.png"/>


---


## Challenge #1

.center[
<iframe width="600" height="420" src="https://www.youtube.com/embed/1aVNRZtxeIU?rel=0" frameborder="0" allowfullscreen></iframe>
]


Goal: Confirming anatomical hypotheses on a Teravoxel volume in a reproducible and extensible fashion.


---

## Challenge #2


.center[
<iframe width="720" height="400" src="https://www.youtube.com/embed/jziqfFp9Rq0" frameborder="0" allowfullscreen></iframe>
]

Goal: Build a taxomony of synapses through the analysis and clustering of conjugate EM and array tomography.

---

<img src="images/ocp.png" alt="Drawing" style="width: 700px;"/>

<br> 

Founded to create an infrastructure for the __open-science, data-intensive analysis of electron microscopy brain data__
- peta-scale storage linked to HPC
- computational vision workflows to extract brain structure
- spatial queries (clusters, volumes, distributions) for analysis

Evolved into an end-to-end (from microscope output to publication) platform for data management and reproducible science
- visualiztion in 2-d and 3-d with mobile support
- image processing: stitching, alignment, registration, color correction 
- cloud-based storage, processing, and caching
- Web-services back end for many visualization tools ([BigDataViewer](https://imagej.net/BigDataViewer), [CATMAID](http://catmaid.readthedocs.io/), [NeuroGlancer](https://neuroglancer-demo.appspot.com/))

---

### OCP Architecture (ca. 2013)

<br> 

Scale-out storage clusters that provide data through Web services
- cutout: read a spatial volume of data
- annotate: label regions of space (store superpixelations)
- query: shapes, objects metadata

<br>

.left[
<img src="images/ocp2013.png" alt="Drawing" style="width: 700px;"/>
]

<br> 

Had to move lots of data across networks to make workflows runs.

---

### To The Cloud: NeuroData 2016

<br> 

Co-developed (shared code base) with the IARPA MICrONS [BOSS](https://api.theboss.io/)
- Post images from microscope to S3
- Process and share with AWS services
- Cloud-based interactive data analysis (Jupyter)

<br>

.left[
<img src="images/ocp2013.png" alt="Drawing" style="width: 700px;"/>
]

---

### NeuroDataViz

<br> 

Web-enabled maps style viewer with support for:
- browser driven image processing
- layered datasets (EM+annotations and multi-channel)
- 2-d tiles and 3-d volumes data engines 
- object metadata and searching, in neural ontology

.center[
<img src="images/ndpaper-fig2c.png" alt="Drawing" style="width: 600px;"/>
]

.cbar[
[@alexbaden](https://github.com/alexbaden):
[<i class="fa fa-gamepad" aria-hidden="true"></i>](http://ix.neurodata.io) 
| [<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/NeuroDataViz/issues)
]

---
### NeuroDataViz with Google's NeuroGlancer

<br>

.center[
<iframe width="672" height="378" src="https://www.youtube.com/embed/WGY2-RE_bYI" frameborder="0" allowfullscreen></iframe>
]
3-d data are loaded as subvolume (cuboids) from NeuroData store.

---

### NDViz Metadata and Image Processing

.center[
<iframe width="672" height="378" src="https://www.youtube.com/embed/OhN4Flemg-o" frameborder="0" allowfullscreen></iframe>
]

Conjugate EM, array tomography, and annotated synapse labels.  Good visual products require image processing in browser.

---

### Transformations in the Cloud

<br>

Adopt the [Render Service](https://github.com/saalfeldlab/render) from [Janelia](http://www.janelia.org)
- apply a lineage of image transformations on demand
- materialize any stage of image processing

.center[
<img src="images/render-components.png" alt="Drawing" style="width: 500px;"/>
]

.cbar[
[@troutmane](https://github.com/troutmane)
]

---
### The Render Workflow

<br> 

Metadata describing relationships between source images and aligned and corrected stacks.

.center[
<img src="images/renderalign.png" alt="Drawing" style="width: 600px;"/>
]

.cbar[
[@perlman](https://github.com/perlman)
]

---

### Vizualization of Transformations
<br>
NeuroDataViz can examine any stage of transformations, e.g.
 point match functions prior to elastic correction.  
<img src="images/rotatefull.png" style="width: 750px;"/>
.center[
<img src="images/zoompm.png" style="height: 200px;"/>
]

.cbar[
[@fcollman](https://github.com/fcollman)
]

---

### To The Cloud: NeuroData 2016

<br> 

Co-developed (shared code base) with the IARPA MICrONS [BOSS](https://api.theboss.io/)
- Post images from microscope to S3
- Process and share with AWS services
- Cloud-based interactive data analysis (Jupyter)

<br>

.left[
<img src="images/ocp2013.png" alt="Drawing" style="width: 700px;"/>
]

---

### The NeuroData Storage Hierarchy
<br>

.center[
<img src="images/cloud.storage.png" style="height: 450px;"/>
]
Balance cost/performance/capacity and adapt data placement based on workload.

---

name: ramondb
layout: false

### Neurodata Ontology (RAMON) 
<br>

Links metadata to annotations (supervoxels) in spatial databases.
- Searchable: find objects by property
- Extensible: general key/value metadata  

.center[
<img src="images/ramon.png" style="height: 350px;"/>
]

.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]

---

### Examples of Semantic Queries
<br>
Filter all annotations based on object type
- mitochondria (left)
- vessicles (right)

<br>
.center[
<img src="images/fig5_mitochondria.png" style="height: 250px;"/>
<img src="images/fig5_vesicles.png" style="height: 250px;"/>
]

<br>
.cbar[
[@willgray](https://github.com/willgray):
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/neurodata/ndstore/tree/microns/ramon) 
| [<i class="fa fa-book" aria-hidden="true"></i>](http://docs.neurodata.io/nddocs/ndprocess/ramon.html) 
| [<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/neurodata/ndio/issues/new)
]


---
name: 2d
layout: false


### 2D Color/Intensity Correction

<br>

Automatically remove artifacts from imaging tiles seperately
- Distributed multi-grid Poisson solver

<br>

.center[
<img src="images/A_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
<img src="images/D_dmg_full_section_2402.jpg" alt="Drawing" style="height: 200px;"/>
]
<br>


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/MyPapers/ToG10.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name: 3d

### 3D Color/Intensity Correction

<br>

Automatically remove 3D artifacts in serial sections
- Smooth system in gradient domain to normalize
- Add high-frequencies back in to preseve edges 



<br>

.center[
<img src="images/GDF2.png" alt="Drawing" style="width: 100%;"/>
]

---
name: 3d2

### 3D Color/Intensity Correction

<br>

Automatically remove 3D artifacts in serial sections
- Solve global Poisson system in gradient domain to normalize
- Add high-frequencies back in to preseve edges 

<br>
.center[
<iframe width="560" height="315" src="https://www.youtube.com/embed/TfUNmb5GwGw&showinfo=0" frameborder="0" allowfullscreen></iframe>
]


.cbar[
[@misha](https://github.com/mkazhdan/): 
[<i class="fa fa-code" aria-hidden="true"></i>](http://www.cs.jhu.edu/~misha/Code/GradientDomainFusion/)  | 
[<i class="fa fa-book" aria-hidden="true"></i>](http://arxiv.org/pdf/1506.02079v1.pdf)  | 
[<i class="fa fa-exclamation-circle" aria-hidden="true"></i>](https://github.com/mkazhdan/DMG/issues/new)
]


---
name: r_im

## Image Datasets


.center[
<img src="images/image_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 10+ public datasets
- EM, AT, Ophys, XCT
- 100+ teravoxels
- All "reference" datasets


.cbar[
[<i class="fa fa-external-link" aria-hidden="true"></i> Projects](http://neurodata.io/projects)
]

---
name: r_anno

## Annotation Datasets

.center[
<img src="images/annotation_datasets.png" alt="Drawing" style="width: 700px;"/>
]

- 5 different publications with volumetric annotations
- No skeleton annotations yet
- Volumetric required for training machine vision
- Annotations cross spatiotemporal scale: nano, micro, time-series


---

### Open Science Contributions


- Reference EM and other datasets
- Reference annotations (crucial for training machine learning)
- Reference pipelines for operating on such data
- Web-services for data access
- Comprehensive cloud computing platform

--

<br />

### Implications: it is now easier to


- Answer questions that require scale
- Engage complementary expertise
- Reproduce and extend results

---
name: fam
layout: false
class:  center

# NeuroData Family


.center[
|   |   | |
| :--- | :--- | :--- |
| .r[Collect] | | .r[Clay Reid, Davi Bock, Jeff Licthman, Bobb Kasthuri, Karl Deisseroth, Raju Tomer, Li Ye, Ailey Crow, Ed Boyden, Mike Milham, Cameron Craddock, Stephen Smith, Forrest Collman, Kristen Harris, Scott Emmons, Dan Bumbarger, Mitya Chklovskii, Nikhil Bhatla, Nelson Spruston, Erik Bloss]
| .orange[Store] | | .orange[Randal Burns, Eric Perlman, Kunal Lillaney, Priya Manavalan, Alex Eusman]
| .ye[Explore] | | .ye[Alex Baden,  Ivan Kuznetsov, David Marchette, Leo Duan, Albert Lee]
| .g[Analyze] | &nbsp;&nbsp;&nbsp;&nbsp; | .g[Mike Miller, Nicholas Charon, Misha Kazhdan, Jordan Matelsky, Kwame Kutten, Greg Kiar, Eric Bridgeford, Greg Hager, Will Gray Roncal, Mark Chevillet,  Dean Kleissas, R. Jacob Vogelstein, Guillermo Sapiro, Anish Simhal, Konrad Kording, Eva Dyer]
| .blue[Model] | | .blue[Joshua T. Vogelstein, Carey Priebe, Dan Naiman,  Tyler Tomita, Youngser Park, Jesse L. Patsolic, Leo Duan, Cencheng Shen, Ivan Kuznetsov]
| .purple[Graphs] | | .purple[Da Zheng, Disa Mhembere, Vince Lyzinski, Avanti Athreya, Daniel Sussman, Shangsi Wang, Runze Tang, Minh Tang]
]




---
class:   middle, center


# Questions?

_____

Funding


NIH: {CRCNS, BRAIN, TRA}

NSF:  BIGDATA

DARPA: {XDATA,GRAPHS,SIMPLEX}

IARPA: MICrONS

____


w: [neurodata.io](http://neurodata.io)

d: [docs.neurodata.io](http://docs.neurodata.io)

e: [support@neurodata.io](mailto:support@neurodata.io)


    </textarea>
    <script src="remark-latest.min.js" type="text/javascript">
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured" type="text/javascript"></script>
    <script type="text/javascript">
      var slideshow = remark.create();

      // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });
      MathJax.Hub.Queue(function() {
          $(MathJax.Hub.getAllJax()).map(function(index, elem) {
              return(elem.SourceElement());
          }).parent().addClass('has-jax');
      });

      MathJax.Hub.Configured();

var slideshow = remark.create({
  // Set the slideshow display ratio
  // Default: '4:3'
  // Alternatives: '16:9', ...
  ratio: '4:3',

  // Navigation options
  navigation: {
    // Enable or disable navigating using scroll
    // Default: true
    // Alternatives: false
    scroll: true,

    // Enable or disable navigation using touch
    // Default: true
    // Alternatives: false
    touch: true,

    // Enable or disable navigation using click
    // Default: false
    // Alternatives: true
    click: false
  },

  // Customize slide number label, either using a format string..
  // slideNumberFormat: 'Slide %current% of %total%',
  // .. or by using a format function
  slideNumberFormat: function (current, total) {
    return  current + ' of ' + total;
  },

  // Enable or disable counting of incremental slides in the slide counting
  countIncrementalSlides: false
}); 

    </script>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="js/bootstrap.min.js"></script>
  </body>
</html>
